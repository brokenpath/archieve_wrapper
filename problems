problems
time of original file, "file attributes if tar", "compression level"
tar.XYZ -> zip
zip -> tar.gz
or maybe use lz4 as compression
Minimize "buffering/seek" hard to know we only have filename not filesize.

Archive(ArchiveOutputStream, Iterator[FileInfo, OutputStream]): Unit 
#whos gonna close, might be better to wait if we have to jump when streaming.
#will this make to many filehandlers or something else pop??

(File, ArchiveType, Option[Compression], Mappings)

The mapping structure should be used for "pushing" or 
   pulling using something like monix

a: [abc.zip]/j/[k.tar]/f1 -> [mm1.tar]/f1
b: [abc.zip]/j/[k.tar]/f2 -> [mm2.tar]/[ll2.tar]/f2
Path(archives: Seq[Archive], outputName: String)
I would need to create the archive structure first. Otherwise a reversed tree is needed

-> Use restriction for now,
    subarchives cannot be split into different subarchives 
      only diffent "root" archives. So b: is not allowed
-> Second restriction for now,
   will always write to an archive
-> Third restriction use ArchiveEntry only for now streams for things like s3 streams, can be abstracted later i hope
-> Fourth restriction its 1 -> {0,1} mappings in first version


each entry needs to closed. closeArchiveEntry
each archive should have finish called on it.
https://stackoverflow.com/questions/13461393/compress-directory-to-tar-gz-with-commons-compress

do we care if resources leak untill the end?

for( (entry, stream) <- Unarchieve.open(xyz)){

}



ver. 0A mv files from archive to multiple files
ver. 0B mv rename files from archive to new archive, Repack


